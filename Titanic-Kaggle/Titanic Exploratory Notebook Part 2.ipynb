{"cells":[{"metadata":{"_cell_guid":"f30b003e-4644-435d-a80f-95e9de4bca63","_uuid":"9ea2e1645eb97e64b7c9b16b5ef4b0e8d7944067"},"cell_type":"markdown","source":"# Welcome\n\n### What was previously covered\nIf you are following my work, PERSON WHO FORKED MY NOTEBOOK, I SEE YOU AND I APPRECIATE YOU, you will know that in the previous notebook I covered the general statistics of the variables, definied what the variables meant to me, and explored a few other assumptions.\nThe assumptions are as following: \n- Were women and children ushered off first?\n- Fare, and Class demonstrate wealth, which wealth really mattered?\n- Did people in the same PassengerClass pay the same fare?\n- What does the cabin variable mean?\n\nWhat I found was from the data was that:\nWomen were ushered off first, but I cannot be certain if children were ushered off first. Both fare paid and passenger class were related to survivability where the richer were more likely to survive, and that the passenger class correlation mattered more than fare. People in the same class did not pay the same fare, but across all classes, many paid the minimum amount. And finally, the cabin variable represents locations that the passenger resided in, which can be mapped to a map of the Titanic if someone pleased to do so. \n\nA link to the previous notebook can be accessed below:    \nhttps://www.kaggle.com/karagain/karsten-s-titanic-exploration-notebook\n\n### What will be covered in this Titanic Notebook\nIn this notebook I will explore the following areas in this dataset:\n- The survivability of different classes that paid the same fare. \n- Variable exploration, if I were to use my current knowledge and statistical knowledge, what would I use to build a model?\n- A basic model that uses Heuristics to predict survivability as baselines.\n- A model that beats the heuristic models. "},{"metadata":{"collapsed":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# Data Processing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine Learning Classifiers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\n\n# Package to Access Dataset\nimport os","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"00d26168-7fa0-4191-957e-2fd686e2abf2","_uuid":"22863b5f557b9794ca68caa2932d8c3ee21654f1","trusted":true,"collapsed":true},"cell_type":"code","source":"# Import training Dataset\ndf = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nfull = pd.concat([df, test])","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"554b0baa-3f44-4972-8ddf-7ded6dae8580","_uuid":"ffb2d0321d138bbebb737cde76fc1ce33a8fd402"},"cell_type":"markdown","source":"# Why these Classifiers?\nIf you looked at the packages imported, you would see that I have chosen two classifiers, GaussianNB and LogisticRegression. Both are classifiers that can spit out a binary result whether the individual survives or not. The simplest difference between the two is the Naive Bayes is based on the joint probability (so the prior probability and posterior probability) of the factors in the training data, Logistic Regression is a \"linear\" regression where the classification is determined by the decision boundary of y = 0.5. Since Logistic Regression is linear, the model is fitted by minimizing the squared error of the regression to the training data, and the variables have an \"All Else Equal\" effect on the probability. \n\nThese two classifiers are easy to understand, easy to tune, and are great for learning machine learning. I plan on using these classifiers for a baseline comparison if I participate in the competition. "},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"# Cont. EDA from the last notebook!\n## The survivability of different classes that paid the same fare\nThe last time we were exploring was in the previous notebook where we were left on a cliffhanger. This time I will explore a 3+ dimensional result to really isolate the effect of class on survivability, with fare kept equal"},{"metadata":{"_uuid":"645ed66367a53c2ba41928da0b7ba990a6d9defc","scrolled":true,"_cell_guid":"68b2286c-cbee-4bfa-919d-bbb184c96df6","trusted":true},"cell_type":"code","source":"# Look at the relative distribution for the Fare\ndf.Fare.hist(bins=70)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"683873a51cf36e343c3a875a2c689d2594d85275","_cell_guid":"0b4cdacc-c428-4f8b-9573-a9913e683f6f","trusted":true},"cell_type":"code","source":"# Get a statistical view of how the results are distributed. \ndf.Fare.describe()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"6f91e4701171c8c85eb73799fc772c8da91abb54","scrolled":false,"_cell_guid":"9ff07062-a4b7-4c22-9cda-d8a0ae45c050","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nfare = 5\ndf.Pclass[df.Fare<=fare].hist()\nplt.title('Price Less Than ' + str(fare))\nplt.ylabel('Tickets Purchased')","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"1642584dda48d284166387d693cb5a7f358d2c25","_cell_guid":"425bdb36-e739-4d9a-8401-16ac52c3a59c"},"cell_type":"markdown","source":"From this most recent graph, we can see that there are some people who paid no fare for the results. On top of that, from this article published by Time about the most expensive ticket, we can see that there are other variables that influenced survivability. Servants of very affluent individuals were also able to escape despite their lower class. I feel that any model that I would  conduct on this table will be extremely inaccurate. I will keep that in mind and come back to it at the end of this notebook. \n\nTime Link: http://time.com/money/4283738/titanic-most-expensive-ticket/"},{"metadata":{"_uuid":"c7082cac13a9193014cf39d57eeee3b1f58e1767","scrolled":false,"_cell_guid":"11d0c49f-240e-46d7-8232-eeb0bea9db60","trusted":true},"cell_type":"code","source":"sns.set_style(style='whitegrid')\nfor x in [5, 10, 50, 100, 500, 1000]:\n    sns.factorplot(\"Pclass\", \"Survived\", hue=\"Sex\", data=df[df.Fare<=x], kind=\"bar\", ci=None).fig.suptitle('Fare less than ' + str(x))\n# sns.factorplot(\"Pclass\", \"Survived\", hue=\"Sex\", data=df[df.Fare<=50], kind=\"bar\", ci=None).fig.suptitle('Fare less than 50')\n","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"2d2095cd04eb60608b4f591ca3a1268d34b51dfe","_cell_guid":"d259288b-eead-4a95-ab18-fe518d3ff9a8"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"7bfc9e970246f3439e9e6a7e9ec6651429952a9d","_cell_guid":"bbfd6222-5bd8-44d2-aee2-95a8eda487ca"},"cell_type":"markdown","source":"The following sets of graphs show the probability of that gender surviving given that they paid in a certain level. The less than 1000 fare should encompass what we have covered before, showing that more than 90% of women survived if they were upper or middle class, while men had consistently low levels of less than 40% surviving for any of the classes. \n\nWe saw from an earlier graph of how many people made purchases of tickets, but I was unable to combine those graphs together. I decided not to do so since I have already spent upwards of an hour trying to figure it out, and I feel that my time could be better allocated. \nThe earlier graph shows that there were people making purchases on low fared tickets, but they did not survive despite being of higher class. \n\nIf you tried to check out the results, in the exploratory graph below, the magical numbers for these critical points seem to be at 11 for the middle class, and 27 for the upper class. \n\nOverall the information is conflicting with what is available online, which suggests the price for first class tickets were minimum 30 pounds. \n\nIn conclusion, if we compare the results form the fare ticket being 30 pounds, versus 100 pounds, the survivability probability actually stays mostly the same. The women's probability increased from a high 80% to a low 90% but this can just be noise in the results. So from this analysis on the extended brackets of fare paid and survivability separated by classes, no fare was not a factor in surviving. It makes sense as the price of a ticket is not a great indicator of a person's wealth, compared to what class they belong to, or their associated companies. "},{"metadata":{"_uuid":"107a6888fe0fcad6a302eeb1ad3255cd81b5b58f","_cell_guid":"0a42fbfd-257c-441b-88d5-a4421dcbdcef","trusted":true},"cell_type":"code","source":"# Changing the x variable allows you to view the tickets purchased below that price, and the class survivability probability. \nx = 50\n\ndf.Pclass[df.Fare<=x].hist()\nplt.title('Price Less Than ' + str(x))\nplt.ylabel('Tickets Purchased')\n\nsns.factorplot(\"Pclass\", \"Survived\", hue=\"Sex\", data=df[df.Fare<=x], kind=\"bar\", ci=None).fig.suptitle('Fare less than ' + str(x))\n","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"6b32b93215f07de78f0dd1a092945959b5e8dbc4","_cell_guid":"76ee9dd1-fdc6-4153-bbe5-509e9120bbca"},"cell_type":"markdown","source":"# Model Building\nGiven what we have covered so far, there are a few strong indicators for survivability to build a model. We could use the class, the sex, and the cabins. We will not use the cabins because too many rows of information are missing. \n\nLet's build two simple models."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9dbb5e8250c28236999a5a8767a53137636b41dc"},"cell_type":"code","source":"# Change the strings into numerals so the data can be recognized by the classifiers\ndf.Sex = df.Sex.str.replace('female', '0')\ndf.Sex = df.Sex.str.replace('male', '1')\ndf.Sex = df.Sex.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45e980ac54ae858dd746804a8fd6d719694b152d","_cell_guid":"dcea51c7-6d95-4c13-a052-c61557d097b8","trusted":true},"cell_type":"code","source":"# Separate the two testing cases\ntrain = df[['Pclass', 'Sex']]\n\n# Train and Run the GaussianNB classifier\nfeatures_train, features_test, labels_train, labels_test = train_test_split(train, df.Survived, test_size = 0.3, random_state = 42)\nclf = GaussianNB()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\n\naccuracy_score(labels_test, pred)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c600cd18eea7ac514732b96a8a6cdb441f7f59ba"},"cell_type":"code","source":"clf = LogisticRegression()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\n\naccuracy_score(labels_test, pred)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"99ad36f3156964bce8631c46bd809674a9a2211c"},"cell_type":"markdown","source":"## Qualification\nFor the two classifiers, we yielded the same accuracy. The 80% accuracy for the test set seems pretty good, much higher than a 50% for a truly random guess for a binary result. But is it really?\n\nRecall from the previous notebook, we saw that majority of the survivors were female, or upper class. We expected the classifier to do better than random guesses, but how do the results fare against heuristics?"},{"metadata":{"trusted":true,"_uuid":"8df69de06f948ae500c535df5954de2f18e3d818"},"cell_type":"code","source":"# We recall that from the training data, 577 are men, 314 are female. \ndf.Sex.value_counts()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7b9d7c7031615a0519c9ea9477d46a4bb3b6cf5"},"cell_type":"code","source":"# Visualizations; These graphs show that a large portion of women, and a little portion of men survived. \nplt.figure(figsize=(13,10))\nplt.subplot(231)\nplt.title('Female Survivors')\nplt.bar(['Survived', 'Deceased'],df.Survived[df.Sex == 0].value_counts(normalize=True), color = ['c', 'm'])\n\nplt.subplot(232)\nplt.title('Male Survivors')\nplt.bar(['Deceased', 'Survived'],df.Survived[df.Sex == 1].value_counts(normalize=True), color = ['r', 'b'])","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"269712c26932c2099f64580e91c15e5849dd5735"},"cell_type":"code","source":"# Here I create a new column to compare to Survived\ndf.loc[df.Sex == 0, 'pred'] = 1\ndf.loc[df.Sex == 1, 'pred'] = 0\n\n# Get an accuracy score for those survived and this heuristic test\naccuracy_score(df.Survived, df.pred)","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"6826fff37343b1dc966835172dbfa95744097511"},"cell_type":"markdown","source":"The results show that our guess was negligly better than a heuristic. The two classifiers did better by half a percent. "},{"metadata":{"_uuid":"80b719d41715f22c6435c6fdccb892c5be1c9d28"},"cell_type":"markdown","source":"# Takeaways\nSo in this notebook, we did some more exploring for a question that was thought up in the previous notebook. We created a model, and we compared it to a simple guess model used as a baseline. From this we learned that we need to really improve our analytical ability to make sure we get much better results than two obvious results.\n\n# Next Notebook\nTo improve upon this result, the next notebook will:\n- Explore variables more deeply. Run a generic correlation graph\n- Clean the cabin data so the results are usable\n- Fix the age variable by manually inputting data from online\n- Run a few different models with two more variables and compare. \n- Create another heuristic model that will include a second pivot of class. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}