{"cells":[{"metadata":{"_cell_guid":"50eae321-51f8-440c-b726-5ea33730759e","_uuid":"39873b00bb7a2f2ffaf8f67fea4477a447f9ae0f"},"cell_type":"markdown","source":"# Test\nThe last kernel only got us 77% accuracy on the leaderboards. With our original 84% for our training data, it shows that we are overfitting to the training data. \n\nI would like to improve upon the variables that I collected by creating a child variable if the child is 14 or under, remove a few variables since we are overfitting, and convert the fare to a log scale to separate out the data. I would also like to divide the fare over the number of people on the ticket. "},{"metadata":{"_cell_guid":"b79eda1a-e02e-420d-a444-2744bf494f67","_uuid":"f80f97a21e2fe5007e01666fc788fc92604cc1b4","collapsed":true},"cell_type":"markdown","source":"So take fare, divide over people with the same ticket to get fare per person. Then get the log of that fare?\nFamily size = SibSp + Parch\nTicketFrequency = ticket counts"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":184,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"35454b2816ca3271bce28497d58dd08bb31e57fe"},"cell_type":"code","source":"# Import Raw Datasets\ndf = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":185,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"a27a32ff8c8f395dca51127e430ebba4160ad6f6"},"cell_type":"code","source":"# Fill missing ages by recollecting data\ndf.sort_values('Name', inplace=True)\n\ndef CA(dataframe, index, age):\n    dataframe.loc[index, \"Age\"] = age\n    \nindexmissing = list(df[df.Age.isnull()].index)\nagelist = agelist = [48, 18, 40, 40, 37, 45, 28, 21, 18, 48, 40, 22, 34, 30, 22, 29, 26, 49, 42, 28, 48, 32, 49, 39, 39, 23, np.nan, 18, 46, 28, 19, 21, 37, 29, 45, 33, 21, 22, 43, 20, 21, 26, 29, 7, 35, 19, 46, 23, 44, 20, 22, 40, 22, 22, 41, 41, np.nan, 35, 23, 38, 23, 5, 3, 8, 12, 31, 20, 30, 21, 26, 18, 28, 29, 22, 19, 29, 24, 31, 20, 22, 19, 62, 32, 28, 25, 23, 23, 19, 28, np.nan, 28, 30, 29, 45, 4, 35, 28, 21, 22, 18, 25, 32, 22, 27, 21, 27, 18, 17, 27, 24, 16, 21, 27, 27, 21, 30, 16, 24, 39, 2, 24, np.nan, 29, 27, 27, 30, 18, 69, 45, 30, 49, 39, 30, 30, 47, 19, 5, 8, 14, 20, 18, 16, 19, 16, 22, 42, 55, 22, 40, 20, 42, 20, 37, 57, np.nan, 57, 23, 64, 48, 37, 37, 33, 20, 23, 17, 19, 66, 21, 23, 28, 43, 54, 45, 23, 45, 19, 23]\ntest[test.Age.isnull()].iloc[60:,[1, 2, 3, 4]]\nagelist2 = [32, 48, 17, 36, 26, 24, 37, 27, 47, 32, 32, 23, 23, 31, 29, 21, 28, 25, 20, 24, 37, 20, 25, 25, 24, 26, 40, 23, 44, 59, 30, 18, 31, 36, 26, 20, 17, 10, 43, 63, 31, 29, 41, 20, 26, 25, 32, 21, 34, 8, 25, 20, np.nan, 44, 43, 31, 26, 28, 18, 20, 22, 46, 25, 23, 33, 20, 40, 25, 25, 17, 16, 10, 44, 10, 19, 21, 44, 28, 23, 64, 26, 22, 21, 23, 35, 4]\nindexmissing2 = list(test[test.Age.isnull()].index)\n\nfor x in range(len(indexmissing)):\n    CA(df, indexmissing[x], agelist[x])\nfor x in range(len(indexmissing2)):\n    CA(test, indexmissing2[x], agelist2[x])\n    \ndf.sort_values('PassengerId', inplace=True)","execution_count":186,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"803d534805aaff7580a9d9a7b067c0f83ea403db"},"cell_type":"code","source":"# Combine datasets\nfull = pd.concat([df, test], ignore_index = True)\nfull.Age = full.Age.fillna(method='backfill')\n\n# Create Family Size Variable\n'''Fsize = SibSp + Parch'''\nfull['Fsize'] = full.SibSp + full.Parch\n\n","execution_count":187,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"\n# Ticket Frequency\ntcountdf = pd.DataFrame(full.Ticket.value_counts())\ntcountdf['TicketC'] = tcountdf['Ticket'].copy()\ntcountdf['Ticket'] = tcountdf.index\nfull = pd.merge(full, tcountdf, how='left', on='Ticket')\nfull.TicketC.astype('int')\n\n# Get FarePer\nfull['FarePer'] = (full.Fare + 0.01)/(full.TicketC)\nfull['LogFarePer'] = np.log(full.FarePer)\nfull['LogFarePer'] = full['LogFarePer'].fillna(value=0)\n","execution_count":188,"outputs":[]},{"metadata":{"_cell_guid":"509a6eec-44be-4148-acef-f7b93741fc3e","_uuid":"78a42c80e6b4da9cb98b382be6ec9cb3738a2338","collapsed":true,"trusted":true},"cell_type":"code","source":"# Convert to category 0,   1, 2, 3, 4, 5+\nfull.loc[full['Fsize'] >= 5, 'cFsize'] = 'Large'\nfull.loc[full['Fsize'] == 0, 'cFsize'] = 'Alone'\nfull.loc[full['Fsize'] == 1, 'cFsize'] = 'Single'\nfull.loc[full['Fsize'] == 2, 'cFsize'] = 'Double'\nfull.loc[full['Fsize'] == 3, 'cFsize'] = '3'\nfull.loc[full['Fsize'] == 4, 'cFsize'] = '4'\n# full.cFsize = full.cFsize.astype(dtype='category', ordered=False, categories=[0, 1, 2, 3, 4, 5])\nfull.cFsize = full.cFsize.astype('category')","execution_count":189,"outputs":[]},{"metadata":{"_cell_guid":"5bd67458-1b6b-4138-89ea-a292626b3074","_uuid":"1b9e16f86c1aac558d39655b56f54cd97bd0d723","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"cFsizeD = pd.get_dummies(full.cFsize, prefix='cFsize').iloc[:, 1:]\nfull = pd.concat([full, cFsizeD], axis=1)","execution_count":190,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"4162b30ba7591a92a4acaee17218ec91c5ee7172"},"cell_type":"code","source":"# Convert strings to dummy variables\nfull.Sex = full.Sex.str.replace('female', '0')\nfull.Sex = full.Sex.str.replace('male', '1')\nfull.Sex = full.Sex.astype('int')\n\n# Create Free Dummy for 0 Fare anomalys, convert 0 fare to Null\nfull.loc[full.Fare == 0, 'Free'] = 1\nfull.loc[full.Fare != 0, 'Free'] = 0\n# full.loc[full.Fare == 0, 'Fare'] = 'NaN'\n\nfull['Age'] = full['Age'].astype(int)\nfull.loc[(full.Age <= 14), 'Minor'] = 1\nfull.loc[(~(full.Age <= 14), 'Minor')] = 0\nfull.Minor = full.Minor.astype('int')\n\nfull.loc[(full.Age >= 40), 'Old'] = 1\nfull.loc[(~(full.Age >= 40), 'Old')] = 0\nfull.Old = full.Old.astype('int')\n\n# Pull out tickets that multiple passengers hold, create dummy variable\nfull.loc[full.Ticket.duplicated(keep=False), 'Group'] = 1\nfull.loc[~full.Ticket.duplicated(keep=False), 'Group'] = 0\n\n\n# Those who are traveling alone\nfull.loc[(full.SibSp == 0) & (full.Parch == 0), 'Alone'] = 1\nfull.loc[~((full.SibSp == 0) & (full.Parch == 0)), 'Alone'] = 0","execution_count":191,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"78bd06952f1138fb0bb8ad901f0ce314a9ed09bb"},"cell_type":"code","source":"tempdf = pd.DataFrame(full.Ticket.value_counts().sort_index())\ntempdf.reset_index(inplace=True)\n# Extract integers\ntempdf['ticketint'] = tempdf.iloc[:, 0].str.extract('.*?(\\d*$)\\s*?', expand = False)\ntempdf.iloc[787, 2] = 1 # To fix the broken ticket of LINE\ntempdf['ticketint'] = tempdf['ticketint'].astype(int)\n# Use consecutive test\ntempdf.loc[((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 1\ntempdf.loc[~((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 0\n# For matching names, pull over the results back to dataframe by testing which ticket is in that Series\nfull.loc[full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index']), 'hasCons'] = 1\nfull.loc[~(full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index'])), 'hasCons'] = 0\n\n# I understand that two chunks of this code is unnecessary, \n# but again, for the sake of preserving my current way of thinking, \n# I will leave it be and optimize the process in another notebook. \n","execution_count":192,"outputs":[]},{"metadata":{"_cell_guid":"29aa2d41-10d3-4ce3-974d-2881a3c56b24","_uuid":"4f82c50e6e42133defb153d4b21f3ea5c48419d9","collapsed":true,"trusted":true},"cell_type":"code","source":"\n# Set all members in the groups with a new dummy variable for condition of other members of group\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'Group'] == 1:\n        groupdf = full[full.Ticket == full.loc[i, 'Ticket']] # This is one row from this full dataframe that is a group\n        b, _ = groupdf.shape\n        indexlist = np.array(groupdf.index)\n        for j in indexlist: # This grabs the rows in the group.\n            if full.loc[j, 'Sex'] == 1: # Passenger is male\n                if full.loc[j, 'Survived'] == 1: # Passenger Survived\n                    full.loc[indexlist[indexlist != j], 'MSG'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'MDG'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n                else: # This scenario is when survived is unknown. \n                    full.loc[indexlist[indexlist != j], 'MUG'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n            else: # Passenger is female\n                if full.loc[j, 'Survived'] == 1: # Passenger survived\n                    full.loc[indexlist[indexlist != j], 'FSG'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'FDG'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n                else:   \n                    full.loc[indexlist[indexlist != j], 'FUG'] = 1 # Others in group gets assigned a Female Unknown Group Dummy\n                    \n# Set all members with consecutive tickets with a new dummy variable for condition of statuses of other consecutive members\n\n# Add new column with all the ticket integers\nfull['ticketint'] = full.loc[:, \"Ticket\"].str.extract('.*?(\\d*$)\\s*?', expand = False)\nfull.loc[full.Ticket == 'LINE', 'ticketint'] = 1 # Fix Line ticket integer\nfull['ticketint'] = full['ticketint'].astype(int) # Set ticketint to int from string\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'hasCons'] == 1: # Passenger has a consecutive ticket\n        consdf = full[(full.ticketint == full.loc[i, 'ticketint']+1) | (full.ticketint == full.loc[i, 'ticketint']-1)]\n        indexlist = np.array(consdf.index)\n        if full.loc[i, 'Sex'] == 1: # Passenger is male\n            if full.loc[i, 'Survived'] == 1: # Passenger Survived\n                full.loc[indexlist, 'MSC'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'MDC'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n            else: # This scenario is when survived is unknown. \n                full.loc[indexlist, 'MUC'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n        else: # Passenger is female\n            if full.loc[i, 'Survived'] == 1: # Passenger survived\n                full.loc[indexlist, 'FSC'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'FDC'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n            else:   \n                full.loc[indexlist, 'FUC'] = 1 # Others in group gets assigned a Female Unknown Group Dummy\n                \nfull[['FSG', 'MUG', 'MDG', 'FDG', 'MSG', 'FUG', \n      'MDC', 'FSC', 'FDC', 'MSC', 'MUC', 'FUC']] = full[['FSG', 'MUG', 'MDG', \n      'FDG', 'MSG', 'FUG', 'MDC', 'FSC', 'FDC', 'MSC', 'MUC', 'FUC']].fillna(value=0)\nfull['Age'] = full['Age'].fillna(full['Age'].mean())\nfull['Fare'] = full['Fare'].fillna(full['Fare'].mean())\n\nfull[['Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n        'FDG', 'MSG', 'FUG', 'MDC',\n        'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']] = full[['Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n        'FDG', 'MSG', 'FUG', 'MDC',\n        'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']].astype(int)\n","execution_count":193,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a28f8e396dacefbc80c55e7e2a61a77e6a301c5"},"cell_type":"code","source":"# FMSG - survived\n# FMSC - survived\n# FMDG - nothing\n# FMDC - slightly likely to die\n\n# FFSG - likely to survive\n# FFSC - likely to survive\n# FFDG - likely to die\n# FFDC - slightly likely to survive\n\n\n# MFSG - nothing\n# MMSG - likely to survive\n# MFDG - dead\n# MMDG - likely to die\n# MFSC - nothing\n# MMSC - likely to survive\n# MFSC - nothing\n# MFDC - nothing\n\n\nfull.loc[(full.Sex == 0) & (full.MSG == 1), 'FMSG'] = 1\nfull.loc[(full.Sex == 0) & (full.MSC == 1), 'FMSC'] = 1\nfull.loc[(full.Sex == 0) & (full.MDG == 1), 'FMDG'] = 1\nfull.loc[(full.Sex == 0) & (full.MDC == 1), 'FMDC'] = 1\nfull.loc[(full.Sex == 0) & (full.FSG == 1), 'FFSG'] = 1\nfull.loc[(full.Sex == 0) & (full.FSC == 1), 'FFSC'] = 1\nfull.loc[(full.Sex == 0) & (full.FDG == 1), 'FFDG'] = 1\nfull.loc[(full.Sex == 0) & (full.FDC == 1), 'FFDC'] = 1\n\nfull.loc[(full.Sex == 1) & (full.MSG == 1), 'MMSG'] = 1\nfull.loc[(full.Sex == 1) & (full.MSC == 1), 'MMSC'] = 1\nfull.loc[(full.Sex == 1) & (full.MDG == 1), 'MMDG'] = 1\nfull.loc[(full.Sex == 1) & (full.MDC == 1), 'MMDC'] = 1\nfull.loc[(full.Sex == 1) & (full.FSG == 1), 'MFSG'] = 1\nfull.loc[(full.Sex == 1) & (full.FSC == 1), 'MFSC'] = 1\nfull.loc[(full.Sex == 1) & (full.FDG == 1), 'MFDG'] = 1\nfull.loc[(full.Sex == 1) & (full.FDC == 1), 'MFDC'] = 1\n\nfull['FMSG'] = full['FMSG'].fillna(value = 0).astype(int)\nfull['FMSC'] = full['FMSC'].fillna(value = 0).astype(int)\nfull['FMDG'] = full['FMDG'].fillna(value = 0).astype(int)\nfull['FMDC'] = full['FMDC'].fillna(value = 0).astype(int)\nfull['FFSG'] = full['FFSG'].fillna(value = 0).astype(int)\nfull['FFSC'] = full['FFSC'].fillna(value = 0).astype(int)\nfull['FFDG'] = full['FFDG'].fillna(value = 0).astype(int)\nfull['FFDC'] = full['FFDC'].fillna(value = 0).astype(int)\n\nfull['MMSG'] = full['MMSG'].fillna(value = 0).astype(int)\nfull['MMSC'] = full['MMSC'].fillna(value = 0).astype(int)\nfull['MMDG'] = full['MMDG'].fillna(value = 0).astype(int)\nfull['MMDC'] = full['MMDC'].fillna(value = 0).astype(int)\nfull['MFSG'] = full['MFSG'].fillna(value = 0).astype(int)\nfull['MFSC'] = full['MFSC'].fillna(value = 0).astype(int)\nfull['MFDG'] = full['MFDG'].fillna(value = 0).astype(int)\nfull['MFDC'] = full['MFDC'].fillna(value = 0).astype(int)","execution_count":300,"outputs":[]},{"metadata":{"_cell_guid":"443f0d9d-9476-44a4-9da4-b777654b31c4","_uuid":"ba76bb4971b208e9303df932c982b40ee491541a","trusted":true},"cell_type":"code","source":"full.iloc[:, :15].head()","execution_count":194,"outputs":[]},{"metadata":{"_cell_guid":"1544a63f-b554-4cab-be50-825ede1f2b8a","_uuid":"112b874f9e7ff117742aa5031d95c47dc9f4175c","scrolled":false,"trusted":true},"cell_type":"code","source":"full.iloc[:, 15:30].head()","execution_count":195,"outputs":[]},{"metadata":{"_cell_guid":"93b944b3-3673-4599-b29f-e1f9a593893d","_uuid":"ac7f288f9f32c04533db8b26847997a184f1070f","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"# Separate the full dataset that has new features into training and testing data. \ntraindf = full.iloc[:891, :]\ntestdf = full.iloc[891:, :]\n\n# cols = ['Age', 'Pclass', 'Sex', 'TicketC', 'Minor', 'SibSp', 'Parch', \n#         'Free', 'FSG', 'MDG', \n#         'FDG', 'MSG', 'MDC', 'MUG', 'FUG', 'MUC', 'FUC', \n#         'FSC', 'FDC', 'MSC', 'cFsize_4', 'cFsize_Alone', 'cFsize_Double', 'cFsize_Large', 'cFsize_Single']\n# No Consecutive\n# cols = ['Pclass', 'Sex', 'TicketC', 'Minor', 'Old', 'SibSp', 'Parch', 'LogFarePer', 'Free', 'Group', 'hasCons', \n#         'FSG', 'MSG', 'FSC', 'MSC', 'FDG', 'MDG', 'FDC', 'MDC',\n#         'cFsize_4', 'cFsize_Alone', 'cFsize_Double', 'cFsize_Large', 'cFsize_Single']\ncols = ['Age', 'Pclass', 'Sex', 'TicketC', 'Minor', 'Old', 'SibSp', 'Parch', 'LogFarePer', 'Free', 'hasCons',\n        'FMSG', 'FMSC', 'FMDG', 'FMDC', 'FFSG', 'FFSC', 'FFDG', 'FFDC', 'MMSG', 'MMSC', 'MMDG', 'MMDC', 'MFSG', 'MFSC', 'MFDG', 'MFDC', \n        'cFsize_4', 'cFsize_Alone', 'cFsize_Double', 'cFsize_Large', 'cFsize_Single']\n\n\ntest = testdf.loc[:, cols]\nfeatures = traindf.loc[:, cols]\nlabels = traindf.loc[:, 'Survived']","execution_count":345,"outputs":[]},{"metadata":{"_cell_guid":"71851e3f-9f23-4c9a-a123-9773a5e86bc7","_uuid":"11894b1ab445d32dcea9b66238fc6ce24d214d53","collapsed":true,"trusted":true},"cell_type":"code","source":"# Splitters\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import train_test_split\n\n# Optimizer\nfrom sklearn.model_selection import GridSearchCV\n\n# Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n# Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_validate","execution_count":355,"outputs":[]},{"metadata":{"_cell_guid":"88681b23-ac75-4c10-9a68-38f5a9745df5","_uuid":"ff2b30a137f6dae161dd5fbce644563cc3d52308","collapsed":true,"trusted":true},"cell_type":"code","source":"features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state=42)","execution_count":347,"outputs":[]},{"metadata":{"_cell_guid":"db45811a-5cbe-4513-93d1-4eb4528d6d1b","_uuid":"7ba5f7e07ceffe7d43fadc95651152c50849f435","scrolled":false,"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf = AdaBoostClassifier(clf, random_state=42)\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nprint(accuracy_score(pred, labels_test))\ncross_validate(clf, features, labels, return_train_score=False, cv=10)","execution_count":348,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"71dc8686dd814e35aedbc6d04159280cbe92dae5"},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf = AdaBoostClassifier(clf, random_state=42)\nclf.fit(features, labels)\npred = clf.predict(test)\n\nclf = LogisticRegression()\nclf.fit(features, labels)\npred2 = clf.predict(test)\n\nclf = RandomForestClassifier()\nclf = AdaBoostClassifier(clf, random_state=42)\nclf.fit(features, labels)\npred3 = clf.predict(test)\n\nclf = KNeighborsClassifier()\nclf.fit(features, labels)\npred4 = clf.predict(test)\n\nclf = SVC()\nclf.fit(features, labels)\npred5 = clf.predict(test)","execution_count":357,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"214067223a82b095799b007acb8ff8bdbed63953"},"cell_type":"code","source":"clfguess = pd.concat([pd.Series(pred), pd.Series(pred2), pd.Series(pred3), pd.Series(pred4), pd.Series(pred5)], axis=1)","execution_count":358,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b436fead37d2ddd1f2e2f9c7dea9d6dc82d00d23"},"cell_type":"code","source":"testdf.iloc[192,:]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b9abd9f79e2d35165fe64fadfff0fb3847d55366"},"cell_type":"code","source":"clfsum = pd.DataFrame(clfguess.sum(axis=1), columns=['Guess'])","execution_count":359,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d72e22aea8f01a4085fc960595f40f6c5e69056"},"cell_type":"code","source":"clfsum.head()","execution_count":360,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"faf2593b1df8270a254a2cfed3a27c6c44ee88c7"},"cell_type":"code","source":"clfsum.loc[clfsum.Guess <= 2, 'pred'] = 0\nclfsum.loc[clfsum.Guess > 2, 'pred'] = 1","execution_count":361,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2f50de0da13ab1c39f09dac63749f42cda580e6c"},"cell_type":"code","source":"clfsum['pred'] = clfsum.pred.astype(int)","execution_count":362,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"0deeba1a0e8ecf22c59c4d2614862577b0247b0f"},"cell_type":"code","source":"my_submission = pd.DataFrame({'PassengerId': testdf['PassengerId'], 'Survived': np.array(clfsum['pred'])})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":363,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25f77dd3935d50c61c49cf91c7ee1df969c4f948"},"cell_type":"code","source":"my_submission","execution_count":364,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2fde2038ca80147313e9fd2795b8521731ce405d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cd93eb68fe8495af6bb04121e07ccbcd9d26c56b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}