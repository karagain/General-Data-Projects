{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# Previous notebook\nWe covered a baseline model that we would like to beat. The 78% accuracy for our training data. We built that classifier based on heuristics that if a person is a female, they would survive. \n\nThe code used to test that is listed below. \n```\n# Change the strings into numerals so the data can be recognized by the classifiers\ndf.Sex = df.Sex.str.replace('female', '0')\ndf.Sex = df.Sex.str.replace('male', '1')\ndf.Sex = df.Sex.astype('int')\n\ndf.loc[df.Sex == 0, 'pred'] = 1\ndf.loc[df.Sex == 1, 'pred'] = 0\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(df.Survived, df.pred)\n```\n\nWe also created a few classifiers using Naive Bayes and Logistic Regression, two simple classification models, and a few variables, Pclass, and Sex. But obviously those variables are not enough, we have many more to explore that can help improve our classifiers accuracy. We are aiming for an 81% accuracy which would put us around 300th place out of 10,000 people, or the 97th precentile. A step towards getting a better result would be to switch classifiers. Naive Bayes is no longer viable because it can always make the wrong prediction, as the results are based on calculated prior and posterior probability. This means that it always has a chance to get a wrong result based on luck and chance. Logistic regression did not have this problem since it used a threshold component of 0.5 that was based on the probabilitistic impact of each of the variables. But in order to improve logistic regression, we we need to explore the features in a polynomial space and gain more explanation to improve accuracy. \n\nIn this notebook, we will look at different classifiers such as adaboost, decision trees, and random forest, and compete their results against the logistic regression training accuracy of 79%. (obviously the training accuracy does not mean that we will do great for the actual test, but it is a measurable metric)\n\nWhat to do today\n- Explore variables more deeply. Run a generic correlation graph\n- Clean the cabin data so the results are usable\n- Fix the age variable by manually inputting data from online\n- Run a few different models with two more variables and compare.\n- Create another heuristic model that will include a second pivot of class."},{"metadata":{"_cell_guid":"b0d9343e-36a8-451a-9298-575a95645c41","_uuid":"05d56253b440ebddda89b3a4a7545c9c77260385"},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"_cell_guid":"ecced965-3987-48f4-9a8e-5221bde74d25","_uuid":"d8613de92650cb6d55fc50ae7794a28adc30b9af","trusted":true},"cell_type":"code","source":"# Import training Dataset\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\ndf = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nfull = pd.concat([df, test], ignore_index = True)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"5ca7c0e8-012f-4968-b82e-19cda6cd0105","_uuid":"25a0f2070e965f03a8a01b8c3008ac6706c01c15"},"cell_type":"markdown","source":"# Recreate Previous Heuristic Model\nRecreating the previous model in this notebook so you do not have to switch back and forth. \nI adapted this model to choose if the passenger was female AND in the higher or middle class, they survived.\n### Code"},{"metadata":{"_cell_guid":"647b0c91-5a06-47ff-a456-7597b27ba805","_uuid":"42d80b2cbf4cc47c89ad30a7e628189e911a84d2","trusted":true},"cell_type":"code","source":"# Change the strings into numerals so the data can be recognized by the classifiers\ndf.Sex = df.Sex.str.replace('female', '0')\ndf.Sex = df.Sex.str.replace('male', '1')\ndf.Sex = df.Sex.astype('int')\n\n# Create \"pred\" column with survivability\ndf.loc[(df.Sex == 0) & (df.Pclass < 3), 'pred'] = 1\ndf.loc[(df.Sex == 1) | (df.Pclass == 3), 'pred'] = 0\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(df.Survived, df.pred)\n\n","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"39e78193-f814-4f90-98b5-7cc0bc1065a0","_uuid":"c4a83e1bbcd943464383b9dd5a39a6a815697128","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"# Remove df predictions\ndf = df.iloc[:, :-1]","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"c1581cc8-55eb-4b7f-8943-fa1f2da04e6d","_uuid":"fc6396c7e76078937f77fecd95eb8c2c713bab80"},"cell_type":"markdown","source":"### Results\nI think it is very interesting how even using a different heuristic, we get the same accuracy for saying survivability for women despite narrowing the results sex with class. The ratio trade off for getting the right answers and the wrong stayed the same. "},{"metadata":{"_cell_guid":"3a0a70a7-c97c-4120-96eb-686c672635ee","_uuid":"c338d4304b6eb4809b26d73cf6d8e6ec0ce73ce6"},"cell_type":"markdown","source":"# Get More Variables\nWe previously Passenger Class and Sex, with a quick touch on Age. We did not see many patterns statistically for age, but I will explore that again because I feel my previous exploration was not enough. We will create a correlation graph to quickly go over all precleaned variables, and explore any basic patterns that appear. \n### Code"},{"metadata":{"_cell_guid":"54be26ce-e097-44ba-8139-6018fd4d6f7f","_uuid":"3dc5b0d8032ef4c36678321a204f62bf64b85343","scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"11973d5b-8cae-46a6-95b1-a1e28bd9ec2a","_uuid":"48ae9fa14f0cde8abd15ea4cc15bd9362c19a690"},"cell_type":"markdown","source":"#### Patterns in the cabin\nA pattern that could exist is just looking at the head of the dataset. Of the three Null values for the Cabin, all of those are are in Pclass 3. Likewise they embarked from S, which is Southampton.\n\n### Code"},{"metadata":{"_cell_guid":"b5fadd8b-b305-4586-9d8d-ab475fbb607f","_uuid":"995f9c50428eadc62626e4f921a685b0e06eb164","scrolled":true,"trusted":true},"cell_type":"code","source":"print(df.Cabin[df.Pclass == 3].value_counts())\nprint('            ')\nprint(df[(df.Cabin.isnull()) & (df.Pclass == 3)].info())\nprint('            ')\nprint(df.Embarked[(df.Cabin.isnull())].value_counts())","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"eb3f7cab-58be-4b78-95be-8546c5f91b5a","_uuid":"5f4dfeafa76338c1bd52c7aeafa116266eee1ac8"},"cell_type":"markdown","source":"Of the lower class, 12 of them had cabins, the remaining were cabinless.  479 people from the training set were not documented. An extra 214 for those in the test set. "},{"metadata":{"_cell_guid":"b089a584-0c7c-4733-a53f-e2c94c6e7940","_uuid":"149736172528d01ff987053f000b918fc081b5e9","scrolled":true,"trusted":true},"cell_type":"code","source":"print(full[(full.Cabin.isnull()) & (full.Pclass == 3)].info())","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"0c795b3e-b6fa-4385-9874-19d3066cb0d6","_uuid":"0053aed8bccd56c027aa78b28ec553dad11b85ca"},"cell_type":"markdown","source":"This is tricky to deal with, because 3rd class passengers were located on all floors, but they were not assigned cabins. There are also others who were in higher classes who were also not assigned cabins, so by having all the results be Null, the learning algorithm may confuse Null with non-surviving. Likewise, since the main holder for tickets in the upperclass are usually men, the females who survive also hold a Null cabin info. \n\nI am unsure on what to do, so I will try two iterations, with cabin information in and without. In the meantime, I will clean it to reflect which section the cabins were in, drop the numbers, then convert the numbers into categorical numbers. \n\n### Code"},{"metadata":{"_cell_guid":"af874ec2-07f4-4d8f-9d02-63490021b452","_uuid":"54d826f439d99ca98b4ae6fdc341ebca09be0b9e","trusted":true},"cell_type":"code","source":"df.Cabin[df.Cabin.notnull()].head(10)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"36a5dfa5-cfd4-449c-ab59-f8ee56585d63","_uuid":"ae2bb3a69eb9c78e7cf1afba81c6844d052d2ee7","scrolled":true,"trusted":true},"cell_type":"code","source":"df['Section'] = df.Cabin.str.extract('(\\w)\\d*', expand = False)\nprint(df.Section[df.Cabin.notnull()].head(10))","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"5fc35e0b-08d1-4d11-ab88-163cee68b123","_uuid":"6cac8dc8a2b5928c08f480bc5dec872089150aac","scrolled":true,"trusted":true},"cell_type":"code","source":"df.iloc[27,:]","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"10e93ddb-4698-454e-8c9c-7a07d4ecf0dd","_uuid":"8760e72f5809f3752ec55d491991136a820d65a7"},"cell_type":"markdown","source":"Cabin extraction was successful, and we also found a young adult who had sisters did not survive. His father did not survive either. It would seem that a male, if with female family members, would not survive. This requires a lot of cleaning, hopefully we will not have to go there to get to the 97th percentile. \n\nWe also need to do the same adjustments to the test set, which will be done later. "},{"metadata":{"_cell_guid":"7257bfb1-935d-4c7d-9950-c8fa1eb25851","_uuid":"35564c6906a271182851850f5ab4b9a498d1a9cc"},"cell_type":"markdown","source":"## General Search"},{"metadata":{"_cell_guid":"51ad5e4f-b05e-4b1b-8a4d-b2872a9ee530","_uuid":"269e67c3fd0ee7f69c5ea0cca89a8823c869e1c1","scrolled":false,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf.corr()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"115dcf01-f640-4117-a411-a443cfd42010","_uuid":"ec3e08f1a304ad1c47271c0ab5d0111ab61ab3c9","trusted":true},"cell_type":"code","source":"full.corr()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"5b91edc0-5451-4ae8-b3fc-8b5b097b9e75","_uuid":"4084e5e740a726e6f6ec29c1a6ada90884d3972c"},"cell_type":"markdown","source":"A few correlation coefficients stand out. \n- Survived vs Pclass, Sex, Fare\n- Pclass vs Sex, Age, and Fare\n- Sex vs SibSp, Parch, Fare\n- Age vs SibSp, Parch\n- SibSp vs Parch, Fare\n- Parch vs Fare\n\nWe looked at Survived vs Pclass, Sex, and Fare already. We found Pclass to be a stronger determinant for survivability, but research would suggest that high Fare outliers stand as an exception.     \nPassenger class tends to be more male in higher classes as shown by a weak positive correlation, older people tend to be in a higher class, and higher class people pay a higher fare. Something to explore is the distribution of gender for classes.     \nFemales were less likely to have siblings or spouses, less parents or children, and paid less.    \nOlder individuals had less siblings or spouses, less parents and children.    \nSiblings or spouses were likely to have parents or children present, and paid a higher fare.    \nParents or children had to pay a higher fare.     \n\nThis is repeated below in a heatmap and again in a scatter histogram matrix.     \nThe heatmap is just a visualization, but does not do a good job because the other weaker positive correlations are drowned out by the hues for a 1:1 correlation. It is unhelpful.      \nThe scatter histogram matrix shows the general distributions, but also that we are dealing with largely categorical variables, the correlations will be easily muddled. For instance, older individuals are more likely to be rich, but younger individuals are more likely to be saved with their mothers. Age brings information, but not so much in a survived vs did not survive correlation form. \n\nWhat we can gather from this as other areas to explore, is that families really need to be grouped together. Fares are higher for sibsp and parch, which suggest one person is paying for everyone else, or the fee is replicated across families. "},{"metadata":{"_cell_guid":"af157b87-ccd2-4154-9ee5-74540d86df91","_uuid":"1d23849e3e6d60e237c616f61fbd6f3a6044cd62","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(231)\nplt.scatter(full.Fare[full.Pclass==1], full.SibSp[full.Pclass==1], alpha=0.5)\nplt.title('Pclass == 1 SibSp')\nplt.subplot(232)\nplt.scatter(full.Fare[full.Pclass==2], full.SibSp[full.Pclass==2], alpha=0.5)\nplt.title('Pclass == 2 SibSp')\nplt.subplot(233)\nplt.scatter(full.Fare[full.Pclass==3], full.SibSp[full.Pclass==3], alpha=0.5)\nplt.title('Pclass == 3 SibSp')\n\nplt.subplot(234)\nplt.scatter(full.Fare[full.Pclass==1], full.Parch[full.Pclass==1], alpha=0.5)\nplt.title('Pclass == 1 ParCh')\nplt.subplot(235)\nplt.scatter(full.Fare[full.Pclass==2], full.Parch[full.Pclass==2], alpha=0.5)\nplt.title('Pclass == 2 ParCh')\nplt.subplot(236)\nplt.scatter(full.Fare[full.Pclass==3], full.Parch[full.Pclass==3], alpha=0.5)\nplt.title('Pclass == 3 ParCh')\n\nplt.show()","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"7e22adec-d2d9-4228-a0ed-7a1d6d8cfe80","_uuid":"decb67c491b2d4c2294d7defbd4d462e057736e5"},"cell_type":"markdown","source":"We can see that at least with the lower class, that the increasing correlation with siblings/spouse and ParCh exists. This does not hold up in higher classes where most people brought 1 or 0 sibsp which could suggest they were single, with a spouse, and no siblings. It would be helpful to have this information split up. Another feat in feature extraction."},{"metadata":{"_cell_guid":"e54971d0-3870-4426-9036-d058f07126d1","_uuid":"1e9de94e7b7302d43b31d968fba85a463d5acea1","scrolled":true,"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr())","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"74e65496-78b7-4c0c-bd22-deb96db49fd8","_uuid":"cd6d462b818e0c9f4547c6e7b67a013703ba52e0","scrolled":true,"trusted":true},"cell_type":"code","source":"pd.plotting.scatter_matrix(df, alpha=0.2, figsize=(10, 10), diagonal='hist')\nplt.show()","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"20f64c83-1be3-4bb2-a33e-83da64817581","_uuid":"3acc52b2669fcc0b6fa46536ead6924ffa575d86"},"cell_type":"markdown","source":"### Age\nA different exploration that should give a clearer picture would be the graph below. It felt against my fiber to think that children were not spared along with women on the titanic."},{"metadata":{"_cell_guid":"77934f7c-ebc0-438f-b92e-5ecdf71dd02e","_uuid":"c70d7f9bfed5b316d76929115bb183f993d373e4","scrolled":false,"trusted":true},"cell_type":"code","source":"df.Age[df.Survived ==1].plot(kind='kde')\ndf.Age[df.Survived ==0].plot(kind='kde')\nplt.legend(['Survived', 'Not'])\nplt.show()","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"0b150793-83f0-46b5-a0d0-e560b06318c7","_uuid":"4b94962871824301a6d375613e807a2df2c7a4b6","scrolled":false,"trusted":true},"cell_type":"code","source":"df.Age.isnull().value_counts()","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"7f5fb9e6-3a21-4919-9eb2-7f60c69198f8","_uuid":"9dcdff3e167590405700c7c41e578e7c9652498e","trusted":true},"cell_type":"code","source":"full.Age.isnull().value_counts()","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"db536fd0-b750-4ecf-ba9c-ef88a3cc3ce4","_uuid":"8866505ecd8e6437e2043e09e4c0ad2cfb6f17f9"},"cell_type":"markdown","source":"There are 263 missing age variables. That is a lot to fill in. But data isn't easy. "},{"metadata":{"_cell_guid":"88aeb1fb-0f86-432d-91d6-9a2fc893413e","_uuid":"e284e5fc535289d7a22a9bf97f973f62f7a1993a","collapsed":true,"trusted":true},"cell_type":"code","source":"df.sort_values('Name', inplace=True)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"077f8e8e-a502-4ec2-8707-3fed5f24f7a8","_uuid":"c24c98bf49f31b47d579794cb8381bb1b62adff8","scrolled":false,"trusted":true},"cell_type":"code","source":"# I used this function to cycle through the ranges\ndf[df.Age.isnull()].iloc[110:130,[2, 3, 4, 5]]\n# full.sort_values('Name')","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"b2883e05-3b48-46b4-9244-df78bffcec59","_uuid":"26272e7db2bbd09f0ecaf45310fd6ad2552f9cd3","collapsed":true,"trusted":true},"cell_type":"code","source":"def CA(index, age):\n    df.loc[index, \"Age\"] = age","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"0e88bb64-d9ba-4a9b-844f-4e9a106bc206","_uuid":"8160bf0d109e7d687a3e4dc7170179a8364319c6","collapsed":true,"trusted":true},"cell_type":"code","source":"indexmissing = list(df[df.Age.isnull()].index)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"252f4f0a-efc7-449e-9530-ee7ea0996cc7","_uuid":"f90e96aa97bc9fea266224b93b39d9946d19d87f","collapsed":true,"trusted":true},"cell_type":"code","source":"agelist = [48, 18, 40, 40, 37, 45, 28, 21, 18, 48, 40, 22, 34, 30, 22, 29, 26, 49, 42, 28, 48, 32, 49, 39, 39, 23, 'NaN', 18, 46, 28, 19, 21, 37, 29, 45, 33, 21, 22, 43, 20, 21, 26, 29, 7, 35, 19, 46, 23, 44, 20, 22, 40, 22, 22, 41, 41, 'NaN', 35, 23, 38, 23, 5, 3, 8, 12, 31, 20, 30, 21, 26, 18, 28, 29, 22, 19, 29, 24, 31, 20, 22, 19, 62, 32, 28, 25, 23, 23, 19, 28, 'NaN', 28, 30, 29, 45, 4, 35, 28, 21, 22, 18, 25, 32, 22, 27, 21, 27, 18, 17, 27, 24, 16, 21, 27, 27, 21, 30, 16, 24, 39, 2, 24, 'NaN', 29, 27, 27, 30, 18, 69, 45, 30, 49, 39, 30, 30, 47, 19, 5, 8, 14, 20, 18, 16, 19, 16, 22, 42, 55, 22, 40, 20, 42, 20, 37, 57, 'NaN', 57, 23, 64, 48, 37, 37, 33, 20, 23, 17, 19, 66, 21, 23, 28, 43, 54, 45, 23, 45, 19, 23]","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"e244e3f0-2b62-449e-a75a-00cd76cfb5fb","_uuid":"39ed22db82958b20cbfc9cc4b9cba794bff3c8f4","scrolled":false,"trusted":true},"cell_type":"code","source":"# For the test set\ntest[test.Age.isnull()].iloc[60:,[1, 2, 3, 4]]","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"05758123-5b17-4f85-8558-2fb58e1122b8","_uuid":"7eac9af6c3d5c6912e9f47ced7ad55b56000be0d","collapsed":true,"trusted":true},"cell_type":"code","source":"agelist2 = [32, 48, 17, 36, 26, 24, 37, 27, 47, 32, 32, 23, 23, 31, 29, 21, 28, 25, 20, 24, 37, 20, 25, 25, 24, 26, 40, 23, 44, 59, 30, 18, 31, 36, 26, 20, 17, 10, 43, 63, 31, 29, 41, 20, 26, 25, 32, 21, 34, 8, 25, 20, 'NaN', 44, 43, 31, 26, 28, 18, 20, 22, 46, 25, 23, 33, 20, 40, 25, 25, 17, 16, 10, 44, 10, 19, 21, 44, 28, 23, 64, 26, 22, 21, 23, 35, 4]\nindexmissing2 = list(test[test.Age.isnull()].index)","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"dd783620-8e20-4a65-8421-a8dd23b13005","_uuid":"e408785cdf97a8fa5da065d7dbadd62f8bc458c6"},"cell_type":"markdown","source":"The code to combine everything should be\n```\nfor x in range(len(indexmissing)):\n    CA(indexmissing[x], agelist[x])\n```"},{"metadata":{"_cell_guid":"a50cc7ab-e792-4e8c-8291-dddf321c1500","_uuid":"1aea520872e8b81feea1b93bc48d26d6f2be6d53"},"cell_type":"markdown","source":"### Results\nThrough that long tedious search for the age. I found out that Miss has many indications, either a young girl, not married, or engaged but not using husbands name. Master always refers to a young boy. I suppose that I would also have to go through the names to collect information. On top of that, I found that people who traveled together had similar ticket numbers. Apparently tickets do matter, so I have to extract features from that variable as well. "},{"metadata":{"_cell_guid":"e3f82519-4262-45e3-a339-a9d6306d5314","_uuid":"c3b9b695c90a874e8c4a66e3e1d0134b6965f487"},"cell_type":"markdown","source":"### Singles"},{"metadata":{"_cell_guid":"185fcef1-e991-4d1f-a7dd-689e1d1434a5","_uuid":"c5f0d996d984673ae9b2e521eb51e3a861e0f2f2","trusted":true},"cell_type":"code","source":"df.loc[(df.SibSp == 0) & (df.Parch == 0), 'Alone'] = 1\ndf.loc[~((df.SibSp == 0) & (df.Parch == 0)), 'Alone'] = 0\ndf[df.Alone.notnull()].tail()","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"93e94f66-ed03-48f7-a2d3-661169a6cf8e","_uuid":"a73d09da409a7f44d041516ba360f523e73dbdba","trusted":true},"cell_type":"code","source":"df.Alone.count()","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"81234b90-b4da-4e12-b63c-a640f90c8253","_uuid":"4d52ce55835ecb9c5acc0c6ce3f729bf54cd04e6","scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(231)\ndf.Survived[df.Alone==1].value_counts().plot(kind='bar')\nplt.title('Alone')\nplt.subplot(232)\nplt.title('With Family')\ndf.Survived[df.Alone==0].value_counts().plot(kind='bar')","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"374c7273-3a80-4e8c-a3b8-abc5bd4de9e9","_uuid":"1b0910a0a74a31a625848634495437e808a91593","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,10))\n\nplt.subplot(231)\nplt.title('Female Fam')\ndf.Survived[(df.Alone==0) & (df.Sex==0)].value_counts().plot(kind='bar')\nplt.subplot(232)\nplt.title('Male Fam')\ndf.Survived[(df.Alone==0) & (df.Sex==1)].value_counts().plot(kind='bar')\nplt.subplot(234)\nplt.title('Female Alone')\ndf.Survived[(df.Alone==1) & (df.Sex==0)].value_counts().plot(kind='bar')\nplt.subplot(235)\nplt.title('Male Alone')\ndf.Survived[(df.Alone==1) & (df.Sex==1)].value_counts().plot(kind='bar')\n\nplt.show()","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"2c8d8185-9cd7-49fd-912a-7599a952d5df","_uuid":"f61ef99cb4bd056ceb9fa9c34dfb9e2b3553e0be"},"cell_type":"markdown","source":"These result suggest that being alone with no family members decreases the chances of survival for both genders proportionally. "},{"metadata":{"_cell_guid":"9f6f8a7d-2707-4a11-b263-d6dec18b20eb","_uuid":"78853c2ef63bb2abdb3eaf5cdbafe930054da8c6"},"cell_type":"markdown","source":"# Tickets\nIt came to my attention that tickets were a good indicator for survivability for groups. If in the group there was a survivor, it is likely to have another. \n\nThis would imply a Nearest Neighbor algorithm for the ticket would be plausible. People who purchase two rooms together at the same time would have their tickets to be very close. In addition, if they embark from the same location, that increases the chance that they are a group. Similarily, if people share a ticket, and one is of the opposite gender, it is likely that the man would not survive, but have the female survive. Finally to continue to add, a closely purchased ticket would mean the lack of information from Cabins can be omitted. Finally if one male did not survive in the training data, that could be generalized to the other males over 18 to also not survive. \n\nYou see a lot of pattern when looking at the tickets. I also found a mislabeled Embarked part. The entry for index 604, a Mr. Harry Homer embarked from Southampton not Charleston.\nAnd there's more. If people have a zero fare"},{"metadata":{"_cell_guid":"666bf403-9da3-4582-ab33-1bc29ab1293d","_uuid":"bd3031e2ce9c8e6d3c03d86358b1e6bae167130c","trusted":true},"cell_type":"code","source":"full.sort_values('Ticket').tail(40)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"1ab0c115-a19f-4501-a141-a749046a07c5","_uuid":"1ae4cd66b47385fd4f36d8dd1c2c599c8823ebc2","collapsed":true},"cell_type":"markdown","source":"Consecutiveness, use something to minus another to say there is an adjacent ticket. \n- Has consecutive\n- Has people on same ticket\n- consecutive survived\n- people on same ticket survived\n- consecutive gender\n- same ticket gender \n\nIf females on same ticket are dead, everyone should be dead.      \nIf male in cabin, female likely to survive. \n\nAt this stage, it seems logical to no longer use Adaboost, Logistic classifier, but a clustering algorithm or a neural net. I would have to do a lot of feature extraction and create a variable that reflects, \"Has people on the same ticket, contains which genders\" and the main feature is pretrained survival. Since we have labels of survival, we should use them. I am unsure how logistic regression will be able to capture that. "},{"metadata":{"_cell_guid":"518e2c77-9d44-4a85-b844-16ea96161965","_uuid":"e73ff4ea4a3c66d3f6ed4660e86a19a7de4b41f0","scrolled":false,"trusted":true},"cell_type":"code","source":"full[full.Fare==0].head(50)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"aa7941ea-c209-4193-83c7-52a46049d0ee","_uuid":"998c6a31037966db3036af0f184b03e9935b8127","collapsed":true},"cell_type":"markdown","source":"I am looking at the fare because, there are several of people who have paid 0, and they're all spread out in different classes. But basically all of them passed. One survived, and we have two unknown. Of the unknown, it is a hard guess, Mr. Ismay had many cabins, and he could be like the richest woman on board (read from the link a while ago) and survived by himself, but because he has no fare and shares a ticket with two others who passed, it would seem like he passed as well. Mr. Chisholm on the other hand, has no cabin, shares a consecutive ticket with Parr and Andrews, both who passed, I am much more confident that he has passed as well. \n\nAlso since Fare is normally a continuous variable, by making 0 a discrete variable, we can eliminate the errorneous prediction trend for these passengers with 0 fares. \n\nMaybe use -1, 0, 1\n\nThis is how I will try to clean it. \n- Convert 0 Fare to Null to not affect other fares\n- Create Free dummy for 0 fare\n- Create consecutive variable by taking tickets, sort by tickets, extract rightmost integer part of the string, convert to int, and calculate a difference. If difference is equal to 1 then create consecutive dummy 1\n- Create in group dummy if tickets match someone elses \n- If ticket in test set is consecutive or in a group with trained set, then we can see if already trained people survived or not. So this is why we need to run Ticket as a variable. To create a consecutive variable, you then need to be able to compare to see if the ticket already exists. So maybe we should run the numbers through a set to see if you can get a difference. \n    - My struggle now is finding out how to create the same variables for the test set. \n- Also how do you create a variable that says, someone else in my group/consecutive survived. \n- Female with same ticket is deceased => everyone in that group is dead. \n- Male with same or consecutive ticket survived => everyone in same group or consecutive survived. \n"},{"metadata":{"_cell_guid":"2ddcca1d-d793-4af2-97c2-598452e8d30e","_uuid":"c827eaf377722f11045b149a395a5bb808eaa30f","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create Free Dummy for 0 Fare, convert 0 fare to Null\nfull.loc[full.Fare == 0, 'Free'] = 1\nfull.loc[full.Fare != 0, 'Free'] = 0\nfull.loc[full.Fare == 0, 'Fare'] = 'NaN'","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"5cb6729c-d5cf-45bd-ba4b-5f7eeca9d21e","_uuid":"090684daf1ff2f5d1bb4c22de8dee6168470daa3","collapsed":true,"trusted":true},"cell_type":"code","source":"# Pull out tickets that multiple passengers hold\nfull.loc[full.Ticket.duplicated(keep=False), 'Group'] = 1\nfull.loc[~full.Ticket.duplicated(keep=False), 'Group'] = 0","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"86c2ae85-3830-433d-9ae1-6ff7fa08d9e1","_uuid":"2032ee0db6e5e9a2938466679f6b1ba80c4a8153","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"# Create consecutive variables. It will follow the math as follows\n# g = pd.Series([1, 2, 3, 5, 7, 8, 10]) # Two identical series, when one is offset bothways by 1, does it still exist in the original series.\n# s = pd.Series([1, 2, 3, 5, 7, 8, 10]) # If yes in either direction then it is consecutive. \n# (g-1).isin(s) | (g+1).isin(s)\n\ntempdf = pd.DataFrame(full.Ticket.value_counts().sort_index())\ntempdf.reset_index(inplace=True)\n# Extract integers\ntempdf['ticketint'] = tempdf.iloc[:, 0].str.extract('.*?(\\d*$)\\s*?', expand = False)\ntempdf.iloc[787, 2] = 1 # To fix the broken ticket of LINE\ntempdf['ticketint'] = tempdf['ticketint'].astype(int)\n# Use consecutive test\ntempdf.loc[((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 1\ntempdf.loc[~((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 0\n# For matching names, pull over the results back to dataframe by testing which ticket is in that Series\nfull.loc[full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index']), 'hasCons'] = 1\nfull.loc[~(full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index'])), 'hasCons'] = 0","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"5d432388-cafb-4e2f-a8f8-1862e9fa27ef","_uuid":"dfe3f28b4f8dc226931b57ec8834be1c7c4939c5"},"cell_type":"markdown","source":"### Complex polynomial dummy variables\nAs a male: \n- female survived consecutive/group = ?\n- male survived consecutive/group = likely to live\n- female dead consecutive/group = dead\n- male dead consecutive/group = likely to die\n- male unknown consecutive/group = ?\n- female unknown consecutive/group = ?\n\nAs a female: \n- female survived consecutive/group = likely to live\n- male survived consecutive/group = alive\n- female dead consecutive/group = likely to die\n- male dead consecutive/group = ?\n- male unknown consecutive/group = ?\n- female unknown consecutive/group = ?"},{"metadata":{"_cell_guid":"0e23c135-8225-467d-9465-35bb015bbdec","_uuid":"5a7bda16d71ee6e472d8e31d01a9709204630855","collapsed":true,"trusted":true},"cell_type":"code","source":"pf = (full.Sex == 0)\npm = (full.Sex == 1)\nof = (full.Sex == 0)\nom = (full.Sex == 1)\n\ns = (full.Survived == 1)\nd = (full.Survived == 0)\nu = (full.Survived.isnull())\nc = (full.hasCons == 1)\ng = (full.Group == 1)\n","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"a59f8ac7-4b64-4429-b4fd-54e016d7c2f3","_uuid":"ea682706eeb75462066e25ae800d45009e5c40d5"},"cell_type":"markdown","source":"How do we find if another person other than that person is dead? We have to create a graph of relationships to find out who is consecutive or in the same group. \nSOUNDS LIKE GRAPH THEORY. \n\nIf group = 1, find duplicates of tickets using duplicate function. Get index to find out if they survived, what their gender is.     \nIf hasCons = 1, we need to find a way to find as many consecutive people attached to that one, and repeat for each person. It's inefficient but we only have to run this code once for less than 300 samples. We need to use the tickets, increment by one in either direction, find all people on that ticket, check each of their gender and survival, relay information back as dummy variable, and check an additional increment and repeat. We stop when none are left in initial direction and reverse increments. \n\nNeed a markov chain or something to show who you're friends with. I'm tired of this. \n\n^^^ That section was written two days ago.      \nHow I actually achieved attaching the dummy variables onto other rows of the data was by iterating through the full dataframe, checking if the passenger was in a group, extracting the ticket, creating a dataframe using that ticket, separating the index, and then iterating through the index for the ticket, and assigning the other passengers excluding the original the complex dummy variables. \n\nI went through a similar process for consecutive tickets, which would hopefully also yield information at a smaller scale. "},{"metadata":{"_cell_guid":"731d3cf1-0afd-441e-91ec-70642cc6bf20","_uuid":"f3eff5c6e542bfcddb4406693e31e6d5dd2a5a55","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set all members in the groups with a new dummy variable for condition of other members of group\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'Group'] == 1:\n        groupdf = full[full.Ticket == full.loc[i, 'Ticket']] # This is one row from this full dataframe that is a group\n        b, _ = groupdf.shape\n        indexlist = np.array(groupdf.index)\n        for j in indexlist: # This grabs the rows in the group.\n            if full.loc[j, 'Sex'] == 1: # Passenger is male\n                if full.loc[j, 'Survived'] == 1: # Passenger Survived\n                    full.loc[indexlist[indexlist != j], 'MSG'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'MDG'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n                else: # This scenario is when survived is unknown. \n                    full.loc[indexlist[indexlist != j], 'MUG'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n            else: # Passenger is female\n                if full.loc[j, 'Survived'] == 1: # Passenger survived\n                    full.loc[indexlist[indexlist != j], 'FSG'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'FDG'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n                else:   \n                    full.loc[indexlist[indexlist != j], 'FUG'] = 1 # Others in group gets assigned a Female Unknown Group Dummy","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"e6e6800b-d13c-4d8c-99f1-1dbe743ab46d","_uuid":"3928935e90ad5ad0e610f43b6abeda230d7192cd","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set all members with consecutive tickets with a new dummy variable for condition of statuses of other consecutive members\n\n# Add new column with all the ticket integers\nfull['ticketint'] = full.loc[:, \"Ticket\"].str.extract('.*?(\\d*$)\\s*?', expand = False)\nfull.loc[full.Ticket == 'LINE', 'ticketint'] = 1 # Fix Line ticket integer\nfull['ticketint'] = full['ticketint'].astype(int) # Set ticketint to int from string\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'hasCons'] == 1: # Passenger has a consecutive ticket\n        consdf = full[(full.ticketint == full.loc[i, 'ticketint']+1) | (full.ticketint == full.loc[i, 'ticketint']-1)]\n        indexlist = np.array(consdf.index)\n        if full.loc[i, 'Sex'] == 1: # Passenger is male\n            if full.loc[i, 'Survived'] == 1: # Passenger Survived\n                full.loc[indexlist, 'MSC'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'MDC'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n            else: # This scenario is when survived is unknown. \n                full.loc[indexlist, 'MUC'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n        else: # Passenger is female\n            if full.loc[i, 'Survived'] == 1: # Passenger survived\n                full.loc[indexlist, 'FSC'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'FDC'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n            else:   \n                full.loc[indexlist, 'FUC'] = 1 # Others in group gets assigned a Female Unknown Group Dummy","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"79578491-7e1e-43e2-a0c2-f9a92a1ab49f","_uuid":"a972a0920cce387588a49b67a7bd8ddccfcbbfc5","trusted":true},"cell_type":"code","source":"full.head()","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"32ef15d3-7d39-4aba-9076-f8cff384ada0","_uuid":"b5f22b88fe00fffdeea98e61d726f80711ca0902","collapsed":true,"trusted":true},"cell_type":"code","source":"# # One of the first drafts I went through to pull these blocks of algorithms out. \n# # They took me two days to think of, repeatedly outline, and finally function the way I wanted them to. \n\n# # Show Series of consecutive tickets\n# a = full.Ticket[full.hasCons == 1]\n# # Series of extracted ticket integers\n# b = a.str.extract('.*?(\\d*$)\\s*?', expand = False)\n# # Series + 1\n# c = b + 1\n# # Series for tickets of all plus one consecutives\n# d = c[c.isin(b)]\n# # All the people with these tickets should have their name(unique identifier) gender, and survival extracted. \n# # Or we just find if there is one of the dummy variables true\n\n# # When you have the increments, you can run the same is duplicated command. \n ","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"f6e47818-5aa0-4d4e-89fa-5ea8501ed678","_uuid":"89c7dc24a55a62eef65d8ef9d1a1cf5dbca3fb3f","collapsed":true},"cell_type":"markdown","source":"# Aggregating the cleaning functions\nI only started using the full dataset at the end, because I realized that there was more information to be captured and features to be extracted after I started exploring more. To preserve the workflow that I went through, I will keep the upper section the same and repeat the process down here so that the cleaning algorithms written throughout this notebook  affects all parts of the datasets. In addition, making this section down here will make the predictions on a future date simpler, as I do not have to go to each cleaning section and run the cells, nor run the entire notebook to clean the results in preparation for running a machine learning algorithm. "},{"metadata":{"_cell_guid":"1a3784f3-2edd-4068-8ec2-b60ee21d3254","_uuid":"624b24a3c36919424bdc5bdadc39dda0f7fa034a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Import Raw Datasets\ndf = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"58d744b3-0158-40eb-aa64-1cc99ac95f37","_uuid":"ecb0aee8164e7ce3dea10ef4edde4fb746775670","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"# Fill missing ages by recollecting data\ndf.sort_values('Name', inplace=True)\n\ndef CA(dataframe, index, age):\n    dataframe.loc[index, \"Age\"] = age\n    \nindexmissing = list(df[df.Age.isnull()].index)\nagelist = agelist = [48, 18, 40, 40, 37, 45, 28, 21, 18, 48, 40, 22, 34, 30, 22, 29, 26, 49, 42, 28, 48, 32, 49, 39, 39, 23, np.nan, 18, 46, 28, 19, 21, 37, 29, 45, 33, 21, 22, 43, 20, 21, 26, 29, 7, 35, 19, 46, 23, 44, 20, 22, 40, 22, 22, 41, 41, np.nan, 35, 23, 38, 23, 5, 3, 8, 12, 31, 20, 30, 21, 26, 18, 28, 29, 22, 19, 29, 24, 31, 20, 22, 19, 62, 32, 28, 25, 23, 23, 19, 28, np.nan, 28, 30, 29, 45, 4, 35, 28, 21, 22, 18, 25, 32, 22, 27, 21, 27, 18, 17, 27, 24, 16, 21, 27, 27, 21, 30, 16, 24, 39, 2, 24, np.nan, 29, 27, 27, 30, 18, 69, 45, 30, 49, 39, 30, 30, 47, 19, 5, 8, 14, 20, 18, 16, 19, 16, 22, 42, 55, 22, 40, 20, 42, 20, 37, 57, np.nan, 57, 23, 64, 48, 37, 37, 33, 20, 23, 17, 19, 66, 21, 23, 28, 43, 54, 45, 23, 45, 19, 23]\ntest[test.Age.isnull()].iloc[60:,[1, 2, 3, 4]]\nagelist2 = [32, 48, 17, 36, 26, 24, 37, 27, 47, 32, 32, 23, 23, 31, 29, 21, 28, 25, 20, 24, 37, 20, 25, 25, 24, 26, 40, 23, 44, 59, 30, 18, 31, 36, 26, 20, 17, 10, 43, 63, 31, 29, 41, 20, 26, 25, 32, 21, 34, 8, 25, 20, np.nan, 44, 43, 31, 26, 28, 18, 20, 22, 46, 25, 23, 33, 20, 40, 25, 25, 17, 16, 10, 44, 10, 19, 21, 44, 28, 23, 64, 26, 22, 21, 23, 35, 4]\nindexmissing2 = list(test[test.Age.isnull()].index)\n\nfor x in range(len(indexmissing)):\n    CA(df, indexmissing[x], agelist[x])\nfor x in range(len(indexmissing2)):\n    CA(test, indexmissing2[x], agelist2[x])\n    \ndf.sort_values('PassengerId', inplace=True)","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"b3489650-8df0-48e1-80dd-1e6af26a562e","_uuid":"1013d161f961c8a017fe47f7dc165d0c626d6448","collapsed":true,"trusted":true},"cell_type":"code","source":"# Combine datasets\nfull = pd.concat([df, test], ignore_index = True)\nfull.Age = full.Age.fillna(method='backfill')","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"f75dd259-d48c-4e95-a081-d7b60182fca2","_uuid":"d0adc127b0470a8f4bc8319caadab7fcabfaf866","collapsed":true,"trusted":true},"cell_type":"code","source":"# Convert strings to dummy variables\nfull.Sex = full.Sex.str.replace('female', '0')\nfull.Sex = full.Sex.str.replace('male', '1')\nfull.Sex = full.Sex.astype('int')","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"b98b881d-c404-402c-b1ec-591c3e1f3785","_uuid":"caecbf03915cb9e2091f7f8b7ae6216e4408b4ee","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create Free Dummy for 0 Fare anomalys, convert 0 fare to Null\nfull.loc[full.Fare == 0, 'Free'] = 1\nfull.loc[full.Fare != 0, 'Free'] = 0\n# full.loc[full.Fare == 0, 'Fare'] = 'NaN'","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"913089ae-9b22-44ad-9df3-8981b977e32f","_uuid":"6f28d0355d982663ff2e207a9cf23081d13b13d5","collapsed":true,"trusted":true},"cell_type":"code","source":"# Pull out tickets that multiple passengers hold, create dummy variable\nfull.loc[full.Ticket.duplicated(keep=False), 'Group'] = 1\nfull.loc[~full.Ticket.duplicated(keep=False), 'Group'] = 0","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"cd254155-02a3-423a-a31c-54837e351fdf","_uuid":"082332fe4850bef739bec8bbf79076a135197141","collapsed":true,"trusted":true},"cell_type":"code","source":"# Those who are traveling alone\nfull.loc[(full.SibSp == 0) & (full.Parch == 0), 'Alone'] = 1\nfull.loc[~((full.SibSp == 0) & (full.Parch == 0)), 'Alone'] = 0","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"c9b29473-9821-47dd-b227-67bd2ac73e46","_uuid":"29bc0971e651410d9678d14a37cae1e69ffe1ddd","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create consecutive variables. It will follow the math as follows\n# g = pd.Series([1, 2, 3, 5, 7, 8, 10]) # Two identical series, when one is offset bothways by 1, does it still exist in the original series.\n# s = pd.Series([1, 2, 3, 5, 7, 8, 10]) # If yes in either direction then it is consecutive. \n# (g-1).isin(s) | (g+1).isin(s)\n\ntempdf = pd.DataFrame(full.Ticket.value_counts().sort_index())\ntempdf.reset_index(inplace=True)\n# Extract integers\ntempdf['ticketint'] = tempdf.iloc[:, 0].str.extract('.*?(\\d*$)\\s*?', expand = False)\ntempdf.iloc[787, 2] = 1 # To fix the broken ticket of LINE\ntempdf['ticketint'] = tempdf['ticketint'].astype(int)\n# Use consecutive test\ntempdf.loc[((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 1\ntempdf.loc[~((tempdf.ticketint-1).isin(tempdf.ticketint) | (tempdf.ticketint+1).isin(tempdf.ticketint)), 'hasCons'] = 0\n# For matching names, pull over the results back to dataframe by testing which ticket is in that Series\nfull.loc[full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index']), 'hasCons'] = 1\nfull.loc[~(full.Ticket.isin(tempdf.loc[tempdf.hasCons == 1, 'index'])), 'hasCons'] = 0\n\n# I understand that two chunks of this code is unnecessary, \n# but again, for the sake of preserving my current way of thinking, \n# I will leave it be and optimize the process in another notebook. ","execution_count":46,"outputs":[]},{"metadata":{"_cell_guid":"77222527-4884-4476-addf-5295f89d00b0","_uuid":"830d9fbc3c76120af6652b710275caf3a0b29a04","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set all members in the groups with a new dummy variable for condition of other members of group\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'Group'] == 1:\n        groupdf = full[full.Ticket == full.loc[i, 'Ticket']] # This is one row from this full dataframe that is a group\n        b, _ = groupdf.shape\n        indexlist = np.array(groupdf.index)\n        for j in indexlist: # This grabs the rows in the group.\n            if full.loc[j, 'Sex'] == 1: # Passenger is male\n                if full.loc[j, 'Survived'] == 1: # Passenger Survived\n                    full.loc[indexlist[indexlist != j], 'MSG'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'MDG'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n                else: # This scenario is when survived is unknown. \n                    full.loc[indexlist[indexlist != j], 'MUG'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n            else: # Passenger is female\n                if full.loc[j, 'Survived'] == 1: # Passenger survived\n                    full.loc[indexlist[indexlist != j], 'FSG'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n                elif full.loc[j, 'Survived'] == 0:\n                    full.loc[indexlist[indexlist != j], 'FDG'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n                else:   \n                    full.loc[indexlist[indexlist != j], 'FUG'] = 1 # Others in group gets assigned a Female Unknown Group Dummy","execution_count":47,"outputs":[]},{"metadata":{"_cell_guid":"e0f36c91-3308-401e-9cb7-9ac7b46684d5","_uuid":"dc63b5a7e8b1dd79091a272b4a7b5ad27839b96a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set all members with consecutive tickets with a new dummy variable for condition of statuses of other consecutive members\n\n# Add new column with all the ticket integers\nfull['ticketint'] = full.loc[:, \"Ticket\"].str.extract('.*?(\\d*$)\\s*?', expand = False)\nfull.loc[full.Ticket == 'LINE', 'ticketint'] = 1 # Fix Line ticket integer\nfull['ticketint'] = full['ticketint'].astype(int) # Set ticketint to int from string\n\na, _ = full.shape\nfor i in range(a):\n    if full.loc[i, 'hasCons'] == 1: # Passenger has a consecutive ticket\n        consdf = full[(full.ticketint == full.loc[i, 'ticketint']+1) | (full.ticketint == full.loc[i, 'ticketint']-1)]\n        indexlist = np.array(consdf.index)\n        if full.loc[i, 'Sex'] == 1: # Passenger is male\n            if full.loc[i, 'Survived'] == 1: # Passenger Survived\n                full.loc[indexlist, 'MSC'] = 1 # Others in group gets assigned a Male Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'MDC'] = 1 # Others in group gets assigned a Male Dead Group Dummy\n            else: # This scenario is when survived is unknown. \n                full.loc[indexlist, 'MUC'] = 1 # Others in group gets assigned a Male Unknown Group Dummy\n        else: # Passenger is female\n            if full.loc[i, 'Survived'] == 1: # Passenger survived\n                full.loc[indexlist, 'FSC'] = 1 # Others in group gets assigned a Female Survived Group Dummy\n            elif full.loc[i, 'Survived'] == 0:\n                full.loc[indexlist, 'FDC'] = 1 # Others in group gets assigned a Female Dead Group Dummy\n            else:   \n                full.loc[indexlist, 'FUC'] = 1 # Others in group gets assigned a Female Unknown Group Dummy","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"7db82c49-dbd1-46cc-bbd0-6dbdfaf90755","_uuid":"ee454b07a6e5a99bd986f1b97b34c54701e05b18","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"full[['FSG', 'MUG', 'MDG', 'FDG', 'MSG', 'FUG', \n      'MDC', 'FSC', 'FDC', 'MSC', 'MUC', 'FUC']] = full[['FSG', 'MUG', 'MDG', \n      'FDG', 'MSG', 'FUG', 'MDC', 'FSC', 'FDC', 'MSC', 'MUC', 'FUC']].fillna(value=0)\nfull['Age'] = full['Age'].fillna(full['Age'].mean())\nfull['Fare'] = full['Fare'].fillna(full['Fare'].mean())","execution_count":49,"outputs":[]},{"metadata":{"_cell_guid":"d9dfb8f6-2cb2-4e77-ad95-04b863cf333d","_uuid":"f35932ddf5cc6a363c46d5d8c067b8acd9294007","collapsed":true,"trusted":true},"cell_type":"code","source":"full[['Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n        'FDG', 'MSG', 'FUG', 'MDC',\n        'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']] = full[['Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n        'FDG', 'MSG', 'FUG', 'MDC',\n        'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']].astype(int)\n\nfull['Fare'] = full['Fare'].astype(int)\nfull['Age'] = full['Age'].astype(int)\n","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"f00056c7-e0f6-4d6d-8004-eff3de8fdee9","_uuid":"a1f01801b003de169d7b99996b20e60bfe67b137","collapsed":true},"cell_type":"markdown","source":"# Running Tests Again"},{"metadata":{"_cell_guid":"6401f14e-0ec2-4208-90bd-1f6658cefab2","_uuid":"197404fa49d24f3c053963d96f67225091b87eea","trusted":true},"cell_type":"code","source":"# Splitters\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import train_test_split\n\n# Optimizer\nfrom sklearn.model_selection import GridSearchCV\n\n# Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n# Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_validate","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"913d8a25-e732-4aca-ad9b-524d2a02ef32","_uuid":"fcffeceea171dca83d2ea4def3d6d2ce989eac7e","scrolled":true,"trusted":true},"cell_type":"code","source":"# Separate the full dataset that has new features into training and testing data. \ntraindf = full.iloc[:891, :]\ntestdf = full.iloc[891:, :]\n\n# Find out column names to further split data\nfull.columns","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"0c9262fd-7901-4c8a-b3dc-3b84e2db22c8","_uuid":"c2f8be33e4b8a430cdea0eef28b130f8d6e756ba","collapsed":true,"trusted":true},"cell_type":"code","source":"# How to use ticket as a category variable?\n# Change Embarked to a category variable","execution_count":53,"outputs":[]},{"metadata":{"_cell_guid":"5771e08d-bc25-426a-ba0f-6ffb482640eb","_uuid":"66263a96ab742d4e829042fb8a61f8a0550aeeed","collapsed":true,"trusted":true},"cell_type":"code","source":"# Hold only training variables. This does not include Cabin, Name, PassengerId, or Survived. \n# cols = ['Age', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp', \n#         'Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n#         'FDG', 'MSG', 'FUG', 'MDC',\n#         'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']\ncols = ['Age', 'Pclass', 'Sex', \n        'Free', 'Group', 'hasCons', 'Alone', 'FSG', 'MUG', 'MDG', \n        'FDG', 'MSG', 'FUG', 'MDC',\n        'FSC', 'FDC', 'MSC', 'MUC', 'FUC', 'Alone']\n\ntest = testdf.loc[:, cols]\nfeatures = traindf.loc[:, cols]\nlabels = traindf.loc[:, 'Survived']","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"d150b9eb-b515-4069-9dc8-f6905c621682","_uuid":"d755428aa4d4b2939f0b27deb56ba3480cfe92db","collapsed":true,"trusted":true},"cell_type":"code","source":"features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state=42)\nfeatures_train = features_train.fillna(value=0)","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"65ab4776-c404-4aef-bcff-599bbb5b731b","_uuid":"00786bcd1e26d3f83f03d219923b357f31b02e37","trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nprint(accuracy_score(pred, labels_test))\ncross_validate(clf, features, labels, return_train_score=False, cv=10)","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"bababb0d-f4f8-4749-bd92-0996d4ef7c29","_uuid":"0c89b182f781707888d8b9bc4a859f81498022b4","trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nprint(accuracy_score(pred, labels_test))\ncross_validate(clf, features, labels, return_train_score=False, cv=10)","execution_count":57,"outputs":[]},{"metadata":{"_cell_guid":"0aabe0df-c21c-4e0a-93fc-b58197a51521","_uuid":"2a5015f74c37d039687fdac78430fc848812b9b0","scrolled":true,"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf = AdaBoostClassifier(clf, random_state=42)\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nprint(accuracy_score(pred, labels_test))\ncross_validate(clf, features, labels, return_train_score=False, cv=10)","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"47c6f01e-2f4d-417d-a0a0-e5b8d193d7c2","_uuid":"501aceba55bab8384d4ae1de9930a1c29dc13093","trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier()\nclf.fit(features_train, labels_train)\npred = clf.predict(features_test)\nprint(accuracy_score(pred, labels_test))\ncross_validate(clf, features, labels, return_train_score=False, cv=10)","execution_count":59,"outputs":[]},{"metadata":{"_cell_guid":"47380f39-565b-42f1-abc9-99dd67dccb2a","_uuid":"7d2b464622148933b0f5fef49325291fdea79709","collapsed":true},"cell_type":"markdown","source":"From these results, the scores lie relatively similar. The cross validation leaves us with an average of about 84%. No result showing too great of an accuracy. I guess all I can do is hope for the best. I have most faith in proper fitting for the logistic regression, and the random forests. "},{"metadata":{"_cell_guid":"88933315-28d7-4e81-8824-b42f9e0c74fb","_uuid":"2ba9a40f009bc55537b6251197f24805254b5461","collapsed":true,"trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\nclf.fit(features, labels)\npred = clf.predict(test).astype(int)\npred = pred.astype(int)","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"3edf043b-cc08-42b7-b032-45e981a62a7c","_uuid":"1dfccdbfd1a73408f110401093d23f23d40f9989","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'PassengerId': testdf['PassengerId'], 'Survived': pred})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('logreg.csv', index=False)","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"be90a2dc-8d33-405f-aed1-d3e7c5665e2f","_uuid":"298baf6a2104a0145cc13dd6a1b421c25559c450","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac1fcd5f-f9a1-4fab-845f-3930b8376f17","_uuid":"cd004e3afd0b674238c667624b58c8c6bdb7818e","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"534019de-8722-44e9-97bd-def3a3a2c043","_uuid":"c8e3e87f7a6acabaf804c3485acf013232bc9364","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddc6126b-ba8a-4541-848a-93c9986a76e6","_uuid":"1b8f541a698e1ef3dad54149e1df9e3e9f27cbf7","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}